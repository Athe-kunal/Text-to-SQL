{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import urllib.request\n",
    "import ssl\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    ")\n",
    "import re\n",
    "from sqlalchemy import inspect\n",
    "import sqlalchemy\n",
    "from sqlalchemy import text \n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_stdlib_context\n",
    "html_link = \"https://pages.stern.nyu.edu/~adamodar/New_Home_Page/datacurrent.html\"\n",
    "\n",
    "with urllib.request.urlopen(html_link) as url:\n",
    "    s = url.read()\n",
    "    # I'm guessing this would output the html source code ?\n",
    "    soup = BeautifulSoup(s,\"lxml\")\n",
    "\n",
    "html_table = soup.find_all(\"table\")\n",
    "req_table = html_table[1]\n",
    "hrefs_list = req_table.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_href = {\"US\":[],\"Europe\":[],\"Japan\":[],\"AUS_NZ_CANADA\":[],\"Emerging\":[],\"China\":[],\"India\":[],\"Global\":[]}\n",
    "\n",
    "for i in hrefs_list:\n",
    "    name = i.get_text().strip()\n",
    "    try:\n",
    "        href_attr = i['href']\n",
    "        if href_attr.endswith('.xls'):\n",
    "            if \"US\" in name:\n",
    "                req_href[\"US\"].append(href_attr)\n",
    "            elif \"Europe\" in name:\n",
    "                req_href[\"Europe\"].append(href_attr)\n",
    "            elif \"Japan\" in name:\n",
    "                req_href[\"Japan\"].append(href_attr)\n",
    "            elif \"Aus\" in name:\n",
    "                req_href['AUS_NZ_CANADA'].append(href_attr)\n",
    "            elif \"Emerging\" in name:\n",
    "                req_href['Emerging'].append(href_attr)\n",
    "            elif \"China\" in name:\n",
    "                req_href['China'].append(href_attr)\n",
    "            elif \"India\" in name:\n",
    "                req_href['India'].append(href_attr)\n",
    "            elif \"Global\" in name: \n",
    "                req_href['Global'].append(href_attr)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ssl._create_default_https_context = ssl._create_stdlib_context\n",
    "\n",
    "import os\n",
    "os.makedirs(\"DATA\",exist_ok=True)\n",
    "for country,excel_files in req_href.items():\n",
    "    country_path = os.path.join(\"DATA\",country) \n",
    "    os.makedirs(country_path,exist_ok=True)\n",
    "    for file in excel_files:\n",
    "        file_name = file.split(\"/\")[-1].split(\".\")[0]\n",
    "        full_file_name = os.path.join(country_path,f\"{file_name}.xls\")\n",
    "        resp = requests.get(file,verify=False)\n",
    "        output = open(full_file_name, 'wb')\n",
    "        output.write(resp.content)\n",
    "        output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR Emerging WE HAVE DIRECTORY LEN = 29 and ACTUAL LEN = 29\n",
      "FOR Europe WE HAVE DIRECTORY LEN = 29 and ACTUAL LEN = 29\n",
      "FOR Global WE HAVE DIRECTORY LEN = 29 and ACTUAL LEN = 29\n",
      "FOR AUS_NZ_CANADA WE HAVE DIRECTORY LEN = 29 and ACTUAL LEN = 29\n",
      "FOR China WE HAVE DIRECTORY LEN = 29 and ACTUAL LEN = 29\n",
      "FOR Japan WE HAVE DIRECTORY LEN = 29 and ACTUAL LEN = 29\n",
      "FOR US WE HAVE DIRECTORY LEN = 24 and ACTUAL LEN = 24\n",
      "FOR India WE HAVE DIRECTORY LEN = 29 and ACTUAL LEN = 29\n"
     ]
    }
   ],
   "source": [
    "for country in os.listdir(\"DATA\"):\n",
    "    dir_len = len(os.listdir(os.path.join(\"DATA\",country)))\n",
    "    country_len = len(req_href[country])\n",
    "    print(f'FOR {country} WE HAVE DIRECTORY LEN = {dir_len} and ACTUAL LEN = {country_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emerging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 86.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Europe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 94.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 102.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUS_NZ_CANADA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 104.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 103.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 66.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 102.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 100.35it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "def sanitize_column_name(col_name):\n",
    "    # Remove special characters and replace spaces with underscores\n",
    "    return re.sub(r\"\\W+\", \"_\", col_name)\n",
    "\n",
    "dir = \"DATA2\"\n",
    "processed_dir = \"Processed Data\"\n",
    "all_infos_dict = []\n",
    "os.makedirs(processed_dir,exist_ok=True)\n",
    "for country in os.listdir(dir):\n",
    "    print(country)\n",
    "    file_name = os.path.join(dir,country)\n",
    "    os.makedirs(os.path.join(processed_dir,country),exist_ok=True)\n",
    "    os.makedirs(file_name,exist_ok=True)\n",
    "    for excel_file in tqdm(os.listdir(file_name)):\n",
    "        full_file_name = os.path.join(file_name,excel_file)\n",
    "        xls = pd.ExcelFile(full_file_name)\n",
    "        sns = xls.sheet_names\n",
    "        for sheet_name in sns:\n",
    "            if \"Var\" in sheet_name or \"var\" in sheet_name:\n",
    "                info_df = xls.parse(sheet_name)\n",
    "                info_df = xls.parse(sheet_name)\n",
    "                info_df.dropna(how=\"all\",inplace=True)\n",
    "                info_dict = {}\n",
    "                for cols in info_df.columns:\n",
    "                    if \"End\" not in cols and 'Unnamed' not in cols:\n",
    "                        info_dict['Summary'] = cols\n",
    "                info_dict['Vars'] = info_df.values[1:].tolist()\n",
    "                all_infos_dict.append(info_dict)\n",
    "            elif \"Industry\" in sheet_name or \"industry\" in sheet_name:\n",
    "                data_df = xls.parse(sheet_name)\n",
    "        try:\n",
    "            data_df.dropna(axis=1,thresh=5,inplace=True)\n",
    "            data_df.dropna(inplace=True)\n",
    "            new_header = data_df.iloc[0] #grab the first row for the header\n",
    "        except:\n",
    "            print(full_file_name)\n",
    "            print(data_df)\n",
    "        data_df = data_df[1:] #take the data less the header row\n",
    "        data_df.reset_index(inplace=True,drop=True)\n",
    "        new_header = [sanitize_column_name(str(col)) for col in new_header]\n",
    "        data_df.columns = new_header #set the header row as the df header\n",
    "        save_name = full_file_name.split(\".\")[0].split(\"/\")[-1]\n",
    "        save_file_path = os.path.join(os.path.join(processed_dir,country),save_name)\n",
    "        data_df.to_csv(save_file_path+\".csv\",index=False)\n",
    "        # with open(save_file_path+\".json\", \"w\") as outfile: \n",
    "        #     json.dump(info_dict, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Summary': 'Measures of accounting returns, to all claim holders (and from operations)',\n",
       " 'Vars': [['Number of firms',\n",
       "   'Number of firms in the industry grouping.',\n",
       "   'Law of large numbers?'],\n",
       "  ['R&D Capitalized',\n",
       "   'My estimate of R&D capitalization, based upon a 5-year straight line amortization period, aggregated across firms in the group',\n",
       "   'Capitalized value of R&D gets added on to book equity and to invested capital'],\n",
       "  ['Capitalized R&D as percent of invested capital',\n",
       "   'My R&D capitalization estimate, as a percent of invested capital including that number, based upon aggregated values across firms',\n",
       "   'Magnitude of investment in R&D, relative to investment in more traditional capital expenditures.'],\n",
       "  ['R&D -LTM',\n",
       "   'Aggregated R&D expenses across the last twelve months, across companies in the group.',\n",
       "   'Spending on R&D in most recent year'],\n",
       "  ['R&D: Years minus 1 to minus 5',\n",
       "   'Aggregated R&D expenses for each of the previous five years, across companies in the group.',\n",
       "   'Sepnding on R&D over last five years']]}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_infos_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry_Name</th>\n",
       "      <th>Number_of_Firms</th>\n",
       "      <th>Capital_Expenditures_(US_$_millions)</th>\n",
       "      <th>Depreciation_&amp;_Amort_((US_$_millions)</th>\n",
       "      <th>Cap_Ex/Deprecn</th>\n",
       "      <th>Acquisitions_(US_$_millions)</th>\n",
       "      <th>Net_R&amp;D_(US_$_millions)</th>\n",
       "      <th>Net_Cap_Ex/Sales</th>\n",
       "      <th>Net_Cap_Ex/_EBIT_(1-t)</th>\n",
       "      <th>Sales/_Invested_Capital_(LTM)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advertising</td>\n",
       "      <td>57</td>\n",
       "      <td>775.729</td>\n",
       "      <td>1887.338</td>\n",
       "      <td>0.411018</td>\n",
       "      <td>322.559</td>\n",
       "      <td>75.0800</td>\n",
       "      <td>-0.016886</td>\n",
       "      <td>-0.218120</td>\n",
       "      <td>3.283403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aerospace/Defense</td>\n",
       "      <td>70</td>\n",
       "      <td>10982.128</td>\n",
       "      <td>13311.598</td>\n",
       "      <td>0.825004</td>\n",
       "      <td>10344.750</td>\n",
       "      <td>830.4634</td>\n",
       "      <td>0.022829</td>\n",
       "      <td>0.318077</td>\n",
       "      <td>1.984340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Air Transport</td>\n",
       "      <td>25</td>\n",
       "      <td>25559.725</td>\n",
       "      <td>10609.948</td>\n",
       "      <td>2.409034</td>\n",
       "      <td>368.210</td>\n",
       "      <td>73.5486</td>\n",
       "      <td>0.067203</td>\n",
       "      <td>1.355173</td>\n",
       "      <td>1.777320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apparel</td>\n",
       "      <td>38</td>\n",
       "      <td>1730.981</td>\n",
       "      <td>1386.480</td>\n",
       "      <td>1.248472</td>\n",
       "      <td>38.739</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.072557</td>\n",
       "      <td>1.773076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auto &amp; Truck</td>\n",
       "      <td>34</td>\n",
       "      <td>29899.486</td>\n",
       "      <td>18677.668</td>\n",
       "      <td>1.600815</td>\n",
       "      <td>193.220</td>\n",
       "      <td>983.0696</td>\n",
       "      <td>0.026577</td>\n",
       "      <td>0.675918</td>\n",
       "      <td>1.048732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Industry_Name  Number_of_Firms  Capital_Expenditures_(US_$_millions)  \\\n",
       "0        Advertising               57                               775.729   \n",
       "1  Aerospace/Defense               70                             10982.128   \n",
       "2      Air Transport               25                             25559.725   \n",
       "3            Apparel               38                              1730.981   \n",
       "4       Auto & Truck               34                             29899.486   \n",
       "\n",
       "   Depreciation_&_Amort_((US_$_millions)  Cap_Ex/Deprecn  \\\n",
       "0                               1887.338        0.411018   \n",
       "1                              13311.598        0.825004   \n",
       "2                              10609.948        2.409034   \n",
       "3                               1386.480        1.248472   \n",
       "4                              18677.668        1.600815   \n",
       "\n",
       "   Acquisitions_(US_$_millions)  Net_R&D_(US_$_millions)  Net_Cap_Ex/Sales  \\\n",
       "0                       322.559                  75.0800         -0.016886   \n",
       "1                     10344.750                 830.4634          0.022829   \n",
       "2                       368.210                  73.5486          0.067203   \n",
       "3                        38.739                   0.9474          0.005365   \n",
       "4                       193.220                 983.0696          0.026577   \n",
       "\n",
       "   Net_Cap_Ex/_EBIT_(1-t)  Sales/_Invested_Capital_(LTM)  \n",
       "0               -0.218120                       3.283403  \n",
       "1                0.318077                       1.984340  \n",
       "2                1.355173                       1.777320  \n",
       "3                0.072557                       1.773076  \n",
       "4                0.675918                       1.048732  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Processed Data/US/capex.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILD TABLE NAMES AND METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "',Industry_Name,Number_of_Firms,Capital_Expenditures_(US_$_millions),Depreciation_&_Amort_((US_$_millions),Cap_Ex/Deprecn,Acquisitions_(US_$_millions),Net_R&D_(US_$_millions),Net_Cap_Ex/Sales,Net_Cap_Ex/_EBIT_(1-t),Sales/_Invested_Capital_(LTM)\\n0,Advertising,57,775.729,1887.338,0.4110175283918408,322.559,75.07999999999993,-0.0168860862168837,-0.2181203933865563,3.283403041333076\\n1,Aerospace/Defense,70,10982.128,13311.597999999998,0.8250044810547916,10344.749999999998,830.4633999999933,0.0228292321038578,0.318077061754813,1.9843395804666923\\n2,Air Transport,25,25559.725,10609.948,2.4090339556800844,368.21,73.5486000000019,0.0672027546276203,1.3551729988499104,1.7773199625336142\\n3,Apparel,38,1730.9809999999998,1386.4799999999996,1.2484716692631703,38.739,0.9473999999991064,0.0053650838666078,0.0725567415076527,1.7730762352050575\\n4,Auto & Truck,34,29899.486,18677.668,1.6008147269776931,193.22,983.0695999999988,0.0265766732899557,0.6759175844836917,1.048731678622114\\n5,Auto Parts,39,3565.4210000000007,2034.471,1.7525051966825778,1061.7600000000002,454.9352000000008,0.0316936036463534,0.8398185079860373,2.004790963758861\\n6,Beverage (Alcoholic),19,2244.8160000000007,864.0629999999999,2.59797723082692,1370.0,0.0,0.0939030584900288,0.6367443614850201,0.8968231153352131\\n7,Beverage (Soft),29,7926.687000000001,4543.389,1.7446639501922463,674.6669999999999,7.705600000001141,0.0238699281532688,0.1517545513863501,1.6931990505110932\\n8,Broadcasting,22,1837.548,3387.6400000000003,0.5424271764414165,43.856,0.2399999999997817,-0.0206121524427381,-0.2104150803584717,1.1159893806472496\\n9,Brokerage & Investment Banking,27,7783.945999999999,4646.382,1.675270350134793,876.0999999999999,-189.38079999999945,0.0167661627913481,3.4298253908840737,0.2794992243703733\\n'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10).to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv(override=True)\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "turbo = dspy.OpenAI(model='gpt-3.5-turbo-instruct', max_tokens=250)\n",
    "dspy.settings.configure(lm=turbo)\n",
    "\n",
    "class SQLTableMetadata(dspy.Signature):\n",
    "    \"\"\"Give a suitable table name and description about the given table\"\"\"\n",
    "    pandas_dataframe_str = dspy.InputField(desc=\"First 10 rows of a pandas dataframe delimited by newline character\")\n",
    "    table_name = dspy.OutputField(desc=\"suitable table name\")\n",
    "    table_summary = dspy.OutputField(desc=\"a summary about the table\")\n",
    "\n",
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prog = dspy.ChainOfThought(SQLTableMetadata)\n",
    "    \n",
    "    def forward(self, pandas_dataframe_str):\n",
    "        return self.prog(pandas_dataframe_str=pandas_dataframe_str)\n",
    "\n",
    "cot = CoT()\n",
    "\n",
    "# cot(pandas_dataframe_str = df.head(10).to_csv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [08:18<00:00, 10.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [12:00<00:00, 12.43s/it]\n"
     ]
    }
   ],
   "source": [
    "processed_dir = \"Processed Data\"\n",
    "\n",
    "for country in os.listdir(processed_dir):\n",
    "    country_folder = os.path.join(processed_dir,country)\n",
    "    print(f\"{country}\")\n",
    "    for files in tqdm(os.listdir(country_folder)):\n",
    "        # print(files)\n",
    "        if files.endswith(\".csv\"):\n",
    "            file_name = files.split(\".\")[0]\n",
    "            csv_file_path = os.path.join(country_folder,files)\n",
    "            df = pd.read_csv(csv_file_path,index_col=False)\n",
    "            json_file_path = os.path.join(country_folder,f\"{file_name}.json\")\n",
    "            with open(json_file_path,'r') as f:\n",
    "                data = json.loads(f.read())\n",
    "            if 'table_name' in data and 'table_summary' in data:\n",
    "                # if data['table_name'] == \"\" or data['table_summary'] == \"\":\n",
    "                if data['table_summary'] == \"\":\n",
    "                    pass\n",
    "                else:\n",
    "                    continue\n",
    "            table_preds = cot(pandas_dataframe_str = df.head(10).to_csv())\n",
    "            data['table_name'] = table_preds.table_name\n",
    "            data['table_summary'] = table_preds.table_summary\n",
    "            with open(json_file_path,'w') as f:\n",
    "                json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT TASKS\n",
    "1. Build database with each region for each table\n",
    "2. Embed the table summary and table SCHEMA. Also, embed the table rows\n",
    "3. Retrieval at table level and embed the rows to retrieve relevant rows from the retrieved schema of table\n",
    "4. Final LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a sanitized column name\n",
    "def sanitize_column_name(col_name):\n",
    "    # Remove special characters and replace spaces with underscores\n",
    "    return re.sub(r\"\\W+\", \"_\", col_name)\n",
    "\n",
    "\n",
    "# Function to create a table from a DataFrame using SQLAlchemy\n",
    "def create_table_from_dataframe(\n",
    "    df: pd.DataFrame, table_name: str, engine, metadata_obj\n",
    "):\n",
    "    # Sanitize column names\n",
    "    sanitized_columns = {col: sanitize_column_name(col) for col in df.columns}\n",
    "    df = df.rename(columns=sanitized_columns)\n",
    "\n",
    "    # Dynamically create columns based on DataFrame columns and data types\n",
    "    columns = [\n",
    "        Column(col, String if dtype == \"object\" else Integer)\n",
    "        for col, dtype in zip(df.columns, df.dtypes)\n",
    "    ]\n",
    "\n",
    "    # Create a table with the defined columns\n",
    "    table = Table(table_name, metadata_obj, *columns)\n",
    "\n",
    "    # Create the table in the database\n",
    "    metadata_obj.create_all(engine)\n",
    "\n",
    "    # Insert data from DataFrame into the table\n",
    "    with engine.connect() as conn:\n",
    "        for _, row in df.iterrows():\n",
    "            insert_stmt = table.insert().values(**row.to_dict())\n",
    "            conn.execute(insert_stmt)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATABASE FOR US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir  = \"Processed Data\"\n",
    "def sqlalchemy_engine(region:str):\n",
    "    \"\"\"Create a SQLAlchemy engine for the given region\"\"\"\n",
    "    assert region in os.listdir(processed_dir), f\"{region} is not a valid region from {os.listdir(processed_dir)}\"\n",
    "    engine = create_engine(f\"sqlite:///{region}.db\")\n",
    "    metadata_obj = MetaData()\n",
    "    region_path = os.path.join(processed_dir,region)\n",
    "    dfs = []\n",
    "    for dataframes_path in os.listdir(region_path):\n",
    "        if dataframes_path.endswith(\".csv\"):\n",
    "            df = pd.read_csv(os.path.join(region_path,dataframes_path),index_col=False)\n",
    "            dfs.append((dataframes_path,df))\n",
    "    pbar = tqdm(total=len(dfs),desc=f\"Creating tables for {region}\")\n",
    "    for _, df_table_name in enumerate(dfs):\n",
    "        table_name = df_table_name[0]\n",
    "        table_name = table_name.split(\".\")[0]\n",
    "        df = df_table_name[1]\n",
    "        # print(f\"Creating table: {table_name}\")\n",
    "        create_table_from_dataframe(df,table_name, engine, metadata_obj)\n",
    "        # print(f\"Done creating table for: {table_name}\")\n",
    "        pbar.update(1)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating tables for US: 100%|██████████| 24/24 [00:02<00:00, 11.45it/s]\n",
      "Creating tables for India: 100%|██████████| 29/29 [00:02<00:00, 11.85it/s]\n",
      "Creating tables for China: 100%|██████████| 29/29 [00:02<00:00, 10.64it/s]\n",
      "Creating tables for Europe: 100%|██████████| 29/29 [00:02<00:00, 11.41it/s]\n",
      "Creating tables for Global: 100%|██████████| 29/29 [00:02<00:00, 10.05it/s]\n",
      "Creating tables for AUS_NZ_CANADA: 100%|██████████| 29/29 [00:02<00:00, 12.04it/s]\n",
      "Creating tables for Japan: 100%|██████████| 29/29 [00:02<00:00, 12.06it/s]\n",
      "Creating tables for Emerging: 100%|██████████| 29/29 [00:02<00:00, 11.46it/s]\n"
     ]
    }
   ],
   "source": [
    "us_engine = sqlalchemy_engine(\"US\")\n",
    "india_engine = sqlalchemy_engine(\"India\")\n",
    "china_engine = sqlalchemy_engine(\"China\")\n",
    "europe_engine = sqlalchemy_engine(\"Europe\")\n",
    "global_engine = sqlalchemy_engine(\"Global\")\n",
    "aus_nz_canada_engine = sqlalchemy_engine(\"AUS_NZ_CANADA\")\n",
    "japan_engine = sqlalchemy_engine(\"Japan\")\n",
    "emerging_engine = sqlalchemy_engine(\"Emerging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_infos(sql_engine:sqlalchemy.engine.base.Engine,region:str):\n",
    "    \"\"\"Get all tables in the database\"\"\"\n",
    "    inspector = inspect(sql_engine)\n",
    "    table_names = inspector.get_table_names()\n",
    "    table_infos_dict = {tb: [] for tb in table_names}\n",
    "    for tb in table_names:\n",
    "        column_dict = inspector.get_columns(tb)\n",
    "        schema_str = \"\"\n",
    "        primary_keys = []\n",
    "        for col in column_dict:\n",
    "            schema_str += f\"{col['name']} ({col['type']}), \"\n",
    "            if col[\"primary_key\"] not in primary_keys:\n",
    "                primary_keys.append(col[\"name\"])\n",
    "        with open(os.path.join(processed_dir,region,f\"{tb}.json\")) as f:\n",
    "            table_info = json.loads(f.read())\n",
    "        table_infos_dict[tb] = [\n",
    "            {\n",
    "                \"table_info\": f\"Table {tb} has columns: {schema_str[:-2]}\",\n",
    "                \"table_summary\": f'{table_info[\"Summary\"]}. {table_info[\"table_summary\"]}',\n",
    "            }\n",
    "        ]\n",
    "    return table_infos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_tb_dict = get_table_infos(us_engine,\"US\")\n",
    "india_tb_dict = get_table_infos(india_engine,\"India\")\n",
    "china_tb_dict = get_table_infos(china_engine,\"China\")\n",
    "europe_tb_dict = get_table_infos(europe_engine,\"Europe\")\n",
    "global_tb_dict = get_table_infos(global_engine,\"Global\")\n",
    "aus_nz_canada_tb_dict = get_table_infos(aus_nz_canada_engine,\"AUS_NZ_CANADA\")\n",
    "japan_tb_dict = get_table_infos(japan_engine,\"Japan\")\n",
    "emerging_tb_dict = get_table_infos(emerging_engine,\"Emerging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DollarUS': [{'table_info': 'Table DollarUS has columns: Industry_Name (VARCHAR), Number_of_firms (INTEGER), Average_Company_Age_years_ (INTEGER), Market_Cap_millions_ (INTEGER), Book_Equity_millions_ (INTEGER), Enteprise_Value_millions_ (INTEGER), Invested_Capital_millions_ (INTEGER), Total_Debt_including_leases_millions_ (INTEGER), Revenues_millions_ (INTEGER), Gross_Profit_millions_ (INTEGER), EBITDA_millions_ (INTEGER), EBIT_Operating_Income_millions_ (INTEGER), Net_Income_millions_ (INTEGER)',\n",
       "   'table_summary': 'To report aggregated dollar value of key operating and marker numbers, by industry group, in millions of US $.. This table contains financial information about various industries such as their names, number of firms, average company age, market cap, book equity, enterprise value, invested capital, total debt, revenues, gross profit, EBITDA, EBIT, and net income. The data is delimited by a newline character and can be used for comparison and analysis of the financial performance of different industries.'}],\n",
       " 'EVA': [{'table_info': 'Table EVA has columns: Industry_Name (VARCHAR), Number_of_Firms (INTEGER), Beta (INTEGER), ROE (INTEGER), Cost_of_Equity (INTEGER), _ROE_COE_ (INTEGER), BV_of_Equity (INTEGER), Equity_EVA_US_millions_ (INTEGER), ROC (INTEGER), Cost_of_Capital (INTEGER), _ROC_WACC_ (INTEGER), BV_of_Capital (INTEGER), EVA_US_millions_ (INTEGER), E_D_E_ (INTEGER), Std_Dev_in_Stock (INTEGER), Cost_of_Debt (INTEGER), Tax_Rate (INTEGER), After_tax_Cost_of_Debt (INTEGER), D_D_E_ (INTEGER)',\n",
       "   'table_summary': 'To estimate how much firms earn on their investments, relative to what they need to earn to break even, given the risk.. This table contains financial information for various industries, including the number of firms, return on equity, cost of equity, return on capital, cost of capital, EVA, and debt-to-equity ratio. It can be used to analyze the financial performance of different industries and identify trends and patterns in the data.'}],\n",
       " 'Employee': [{'table_info': 'Table Employee has columns: Industry_Name (VARCHAR), Number_of_firms (INTEGER), Number_of_Employees (INTEGER), Market_Capitalization_millions_ (INTEGER), Revenues_millions_ (INTEGER), Mkt_Cap_per_Employee_ (INTEGER), Revenues_per_Employee_ (INTEGER), Stock_based_Compensation_millions_ (INTEGER), Stock_based_Compensation_as_of_Revenue (INTEGER)',\n",
       "   'table_summary': 'To evaluate how much value and revenue is created by an employee.. This table provides a summary of the top 10 industries, including the number of firms, number of employees, market capitalization, revenues, stock-based compensation, and stock-based compensation as a percentage of revenue. The data is organized in columns, with each row representing a different industry. This table can be used to compare and analyze different industries based on these variables.'}],\n",
       " 'MktCap': [{'table_info': 'Table MktCap has columns: Industry_Name (VARCHAR), Number_of_firms (INTEGER), Quarter_1 (INTEGER), Quarter_2 (INTEGER), Quarter_3 (INTEGER), Quarter_4 (INTEGER), Quarter_12 (INTEGER), Quarter_23 (INTEGER), Quarter_34 (INTEGER), Quarter_45 (INTEGER), 12_31_18 (INTEGER), 12_31_19 (INTEGER), 12_31_20 (INTEGER), 12_31_21 (INTEGER), 12_31_22 (INTEGER), 12_31_23 (INTEGER), 2019 (INTEGER), 2020_0 (INTEGER), 2021_0 (INTEGER), 2022_0 (INTEGER), 2023_0 (INTEGER)',\n",
       "   'table_summary': \"To evaluate how the market's pricing of a sector has changed over time. This table contains information about the financial performance of different industries, including their names, number of firms, and financial data for each quarter and year. The data is organized in a tabular format and can be used to compare the performance of different industries over time.\"}],\n",
       " 'R&D': [{'table_info': 'Table R&D has columns: Industry_Name (VARCHAR), Number_of_firms (INTEGER), R_D_Capitalized_my_estimate_in_millions_ (INTEGER), Capitalized_R_D_as_of_Invested_Capital (INTEGER), R_D_LTM_in_millions_ (INTEGER), Current_R_D_as_of_Revenue (INTEGER), R_D_1_year_ago_in_millions_ (INTEGER), R_D_2_years_ago_in_millions_ (INTEGER), R_D_3_years_ago_in_millions_ (INTEGER), R_D_4_years_ago (INTEGER), R_D_5_years_ago_in_millions_ (INTEGER), CAGR_in_R_D_Last_5_years (INTEGER)',\n",
       "   'table_summary': 'Measures of accounting returns, to all claim holders (and from operations). R&D Investments by Industry\\n\\nTable Summary: This table contains information about the R&D investments made by various industries, including the industry name, number of firms, R&D capitalization, and current and historical R&D data. It can be used for analysis and comparison of R&D trends across industries.'}],\n",
       " 'capex': [{'table_info': 'Table capex has columns: Industry_Name (VARCHAR), Number_of_Firms (INTEGER), Capital_Expenditures_US_millions_ (INTEGER), Depreciation_Amort_US_millions_ (INTEGER), Cap_Ex_Deprecn (INTEGER), Acquisitions_US_millions_ (INTEGER), Net_R_D_US_millions_ (INTEGER), Net_Cap_Ex_Sales (INTEGER), Net_Cap_Ex_EBIT_1_t_ (INTEGER), Sales_Invested_Capital_LTM_ (INTEGER)',\n",
       "   'table_summary': 'To measure how much companies are reinvesting back into their long term assets, as a prelude to forecasting expected growth.. This table contains information about various industries, including the number of firms, capital expenditures, depreciation and amortization, acquisitions, net R&D, and sales. It also includes ratios such as Cap_Ex/Deprecn, Net_Cap_Ex/Sales, Net_Cap_Ex/_EBIT_(1-t), and Sales/_Invested_Capital_(LTM). This table can be used for financial analysis, market research, and investment decisions.'}],\n",
       " 'dbtfund': [{'table_info': 'Table dbtfund has columns: Industry_Name (VARCHAR), Number_of_firms (INTEGER), Book_Debt_to_Capital (INTEGER), Market_Debt_to_Capital_Unadjusted_ (INTEGER), Market_D_E_unadjusted_ (INTEGER), Market_Debt_to_Capital_adjusted_for_leases_ (INTEGER), Market_D_E_adjusted_for_leases_ (INTEGER), Interest_Coverage_Ratio (INTEGER), Debt_to_EBITDA (INTEGER), Effective_tax_rate (INTEGER), Institutional_Holdings (INTEGER), Std_dev_in_Stock_Prices (INTEGER), EBITDA_EV (INTEGER), Net_PP_E_Total_Assets (INTEGER), Capital_Spending_Total_Assets (INTEGER)',\n",
       "   'table_summary': 'To estimate how much debt companies have used in funding, and some of the fundamentals driving that debt choice. . This table contains financial metrics for various industries, including the number of firms, debt and capital ratios, interest coverage, tax rates, institutional holdings, and other financial metrics. It provides a snapshot of the financial health of these industries and can be used for comparison and analysis by investors, researchers, and analysts.'}],\n",
       " 'debtdetails': [{'table_info': 'Table debtdetails has columns: Industry_Name (VARCHAR), Number_of_firms (INTEGER), Lease_Debt_My_Estimate_ (INTEGER), Conventional_Debt (INTEGER), Total_Debt_with_leases (INTEGER), Interest_expense (INTEGER), Book_interest_rate (INTEGER), Short_term_Debt_as_of_Total_Debt (INTEGER), Lease_Debt_Accounting_ (INTEGER)',\n",
       "   'table_summary': 'Details of debt held by firms (lease vs conventional, ST vs LT). Industry Debt Summary\\n\\nTable Summary: This table contains information about the debt of various industries, including the number of firms, different types of debt, interest expenses, and short-term debt as a percentage of total debt. It can be used for financial analysis and comparison of industries.'}],\n",
       " 'divfcfe': [{'table_info': 'Table divfcfe has columns: Industry_name (VARCHAR), Number_of_firms (INTEGER), _Dividends_ (INTEGER), _Net_Income_ (INTEGER), Payout (INTEGER), Dividends_Buybacks (INTEGER), Cash_Return_as_of_Net_Income (INTEGER), Dividends_Buybacks_Stock_Issuances (INTEGER), FCFE_before_debt_cash_flows_ (INTEGER), FCFE_after_debt_cash_flows_ (INTEGER), Net_Cash_Returned_FCFE_pre_debt_ (INTEGER), Net_Cash_Returned_FCFE_post_debt_ (INTEGER), Net_Cash_Returned_Net_Income (INTEGER), Cash_Firm_Value (INTEGER)',\n",
       "   'table_summary': 'To estimate how much companies are returning to shareholders, in both dividends and buybacks, relative to potential dividends (FCFE, i.e., cash left over after taxes, reinvestment and net debt cash flows.). This table provides a summary of the financial performance of various industries, including the number of firms, dividends, net income, payout, cash return, FCFE, and cash/firm value. It contains 10 rows of data, each representing a different industry, and is delimited by a newline character for easy analysis. The table can be used by investors, analysts, and researchers to gain insights into the overall market and make informed decisions about investments.'}],\n",
       " 'divfund': [{'table_info': 'Table divfund has columns: Industry_Name (VARCHAR), Number_of_firms (INTEGER), Total_Dividends_US_millions_ (INTEGER), Special_Dividends_as_of_Total_Dividends (INTEGER), Dividend_Payout (INTEGER), Dividend_Yield (INTEGER), Market_Cap_US_millions_ (INTEGER), ROE (INTEGER), Institutional_Holdings (INTEGER), Std_Dev_in_Stock_Prices (INTEGER)',\n",
       "   'table_summary': 'Fundamental determinants of dividend policy (and payment). This table contains data on the dividend performance of various industries, including the number of firms, total dividends, special dividends, dividend payout, dividend yield, market cap, return on equity, institutional holdings, and standard deviation in stock prices. It can be used for comparison and analysis of the financial health and dividend policies of different industries.'}],\n",
       " 'finflows': [{'table_info': 'Table finflows has columns: Industry_Name (VARCHAR), Number_of_Firms (INTEGER), Dividends_in_millions (INTEGER), Buybacks_in_millions (INTEGER), Equity_Issuance_in_millions (INTEGER), Net_Equity_Change_in_millions (INTEGER), Net_Equity_Change_as_of_Book_Equity (INTEGER), Debt_Repaid_in_millions (INTEGER), Debt_Raised_in_millions (INTEGER), Net_Debt_Change_in_millions (INTEGER), Net_Change_in_Debt_as_of_Total_Debt (INTEGER), Change_in_Lease_Debt_in_millions (INTEGER)',\n",
       "   'table_summary': \"To estimate the sustainable growth rate in earnings per share for a firm, if margins and ROE are stable. If margins are changing, these fundamental growth rates don't apply.. This table contains financial information for various industries, including the number of firms, dividends, buybacks, equity issuance, debt repayment, and debt raised. It also includes the net change in equity and debt as a percentage of total equity and debt, as well as the change in lease debt. This table can be used for financial analysis and comparison of different industries.\"}],\n",
       " 'fundgr': [{'table_info': 'Table fundgr has columns: Industry_Name (VARCHAR), Number_of_Firms (INTEGER), ROE (INTEGER), Retention_Ratio (INTEGER), Fundamental_Growth_ (INTEGER)',\n",
       "   'table_summary': \"To estimate the sustainable growth rate in earnings per share for a firm, if margins and ROE are stable. If margins are changing, these fundamental growth rates don't apply.. This table contains data on the financial performance of various industries, including the number of firms, return on equity, retention ratio, and fundamental growth. It can be used to compare the financial performance of different industries and identify potential investment opportunities.\"}],\n",
       " 'fundgrEB': [{'table_info': 'Table fundgrEB has columns: Industry_Name (VARCHAR), Number_of_Firms (INTEGER), ROC (INTEGER), Reinvestment_Rate (INTEGER), Expected_Growth_in_EBIT (INTEGER)',\n",
       "   'table_summary': \"To estimate the sustainable growth rate in operating income for a firm, if margins and ROC are stable. If margins are changing, these fundamental growth rates don't apply.. This table contains data for the first 10 rows of a dataset that includes information about various industries such as their names, number of firms, return on capital, reinvestment rate, and expected growth in earnings before interest and taxes. It can be used to analyze and compare the performance of different industries and identify trends and patterns in the data.\"}],\n",
       " 'goodwill': [{'table_info': 'Table goodwill has columns: Industry_Name (VARCHAR), Number_of_Firms (INTEGER), Goodwill_in_millions_ (INTEGER), Change_in_Goodwill_in_last_year (INTEGER), Goodwill_as_of_Total_Assets (INTEGER), Impairment_of_Goodwill_in_LTM_in_millioins (INTEGER), Impairment_as_of_Goodwill (INTEGER)',\n",
       "   'table_summary': 'To report historical and expected growth rates in operating metrics. The historical growth rates are compounded, annual values (CAGR).. Goodwill by Industry\\n\\nTable Summary: This table contains data on 10 different industries, including the number of firms, the amount of goodwill, changes in goodwill over the last year, and impairment of goodwill. It has 10 rows and 8 columns, with numerical data for most columns and the industry name as a categorical variable. Notable trends include the high amount of goodwill in the Aerospace/Defense industry and the low amount of impairment in the Bank (Money Center) industry.'}],\n",
       " 'histgr': [{'table_info': 'Table histgr has columns: Industry_Name (VARCHAR), Number_of_Firms (INTEGER), CAGR_in_Net_Income_Last_5_years (INTEGER), CAGR_in_Revenues_Last_5_years (INTEGER), Expected_Growth_in_Revenues_Next_2_years (INTEGER), Expected_growth_in_Revenues_Next_5_years (INTEGER), Expected_Growth_in_EPS_Next_5_years (INTEGER)',\n",
       "   'table_summary': 'To report historical and expected growth rates in operating metrics. The historical growth rates are compounded, annual values (CAGR).. This table contains information about the growth of various industries, including the number of firms, CAGR in net income and revenues over the last 5 years, and expected growth in revenues and EPS over the next 2 and 5 years. It provides a snapshot of the current state and expected future growth of these industries, which can be useful for investors and analysts.'}],\n",
       " 'inshold': [{'table_info': 'Table inshold has columns: Industry_Name (VARCHAR), Number_of_Firms (INTEGER), CEO_Holding (INTEGER), Corporate_Holdings (INTEGER), Institutional_Holdings (INTEGER), Insider_Holdings (INTEGER)',\n",
       "   'table_summary': 'Look at percent of stock held by insiders and institutions, to get a measure of control and corporate governance.. This table provides a summary of the top 10 rows of a dataset containing information about various industries and their holdings, including CEO holdings, corporate holdings, institutional holdings, and insider holdings. It can be used for further analysis and comparison of the different industries.'}],\n",
       " 'leaseeffect': [{'table_info': 'Table leaseeffect has columns: Industry_Name (VARCHAR), Number_of_firms (INTEGER), Lease_Expense_Sales (INTEGER), Total_Debt_without_leases (INTEGER), Total_Debt_with_Leases (INTEGER), Lease_Debt_as_of_Total_Debt (INTEGER), Market_Debt_to_Capital_without_leases (INTEGER), Market_Debt_to_Capital_with_leases (INTEGER), Book_Debt_to_Capital_without_leases (INTEGER), Book_Debt_to_Capital_with_leases (INTEGER), Operating_income_before_lease_adj_ (INTEGER), Operating_income_after_lease_adj_ (INTEGER), ROIC_without_leases_ (INTEGER), ROIC_with_leases_ (INTEGER), Pre_tax_Operating_Margin_before_lease_adj_ (INTEGER), Pre_tax_Operating_Margin_after_lease_adj_ (INTEGER), Lease_Debt_My_Estimate_ (INTEGER), Lease_Debt_Accounting_ (INTEGER)',\n",
       "   'table_summary': 'To estimate what effect treating leases as debt has on key operating and financial numbers.. Industry Financial Performance Summary\\n\\nTable Summary: This table provides a summary of the financial performance of various industries, including their use of leases and their impact on key financial metrics such as debt, operating income, and return on invested capital. It can be used for comparison and analysis of different industries.'}],\n",
       " 'margin': [{'table_info': 'Table margin has columns: Industry_Name (VARCHAR), Number_of_firms (INTEGER), Gross_Margin (INTEGER), Net_Margin (INTEGER), Pre_tax_Pre_stock_compensation_Operating_Margin (INTEGER), Pre_tax_Unadjusted_Operating_Margin (INTEGER), After_tax_Unadjusted_Operating_Margin (INTEGER), Pre_tax_Lease_adjusted_Margin (INTEGER), After_tax_Lease_Adjusted_Margin (INTEGER), Pre_tax_Lease_R_D_adj_Margin (INTEGER), After_tax_Lease_R_D_adj_Margin (INTEGER), EBITDA_Sales (INTEGER), EBITDASG_A_Sales (INTEGER), EBITDAR_D_Sales (INTEGER), COGS_Sales (INTEGER), R_D_Sales (INTEGER), SG_A_Sales (INTEGER), Stock_Based_Compensation_Sales (INTEGER), Lease_Expense_Sales (INTEGER)',\n",
       "   'table_summary': 'Measures of profitability and costs, by industry. This table contains financial information for various industries, including the number of firms and various financial metrics such as gross margin, net margin, and operating margin. It can be used for analyzing the financial performance of different industries and identifying trends and patterns in their financial data.'}],\n",
       " 'optvar': [{'table_info': 'Table optvar has columns: Industry_Name (VARCHAR), Number_of_Firms (INTEGER), Std_Deviation_in_Equity (INTEGER), Std_Deviation_in_Firm_Value (INTEGER), E_D_E_ (INTEGER), D_D_E_ (INTEGER)',\n",
       "   'table_summary': 'To estimate annualized standard deviation in equity and firm values. This table contains financial metrics for various industries, including the number of firms, standard deviation in equity and firm value, and the ratio of equity to debt and debt to equity. The data can be used for analysis and comparison between industries.'}],\n",
       " 'roe': [{'table_info': 'Table roe has columns: Industry_Name (VARCHAR), Number_of_firms (INTEGER), ROE_unadjusted_ (INTEGER), ROE_adjusted_for_R_D_ (INTEGER)',\n",
       "   'table_summary': 'To estimate ratios of market values (equity and firm) to book value (equity and firm), with companion variables (ROE and ROC). This table compares the return on equity (ROE) for the first 10 industries in a dataset, including the industry name, number of firms, and two different measures of ROE (unadjusted and adjusted for R&D expenses). It provides a snapshot of the ROE for each industry, allowing for easy comparison between industries.'}],\n",
       " 'taxrate': [{'table_info': 'Table taxrate has columns: Industry_name (VARCHAR), Number_of_firms (INTEGER), Total_Taxable_Income (INTEGER), Total_Taxes_Paid_Accrual_ (INTEGER), Total_Cash_Taxes_Paid (INTEGER), Cash_Taxes_Accrual_Taxes (INTEGER), Average_across_all_companies (INTEGER), Average_across_only_money_making_companies (INTEGER), Aggregate_tax_rate (INTEGER), Average_across_only_money_making_companies2 (INTEGER), Aggregate_tax_rate3 (INTEGER)',\n",
       "   'table_summary': 'To estimate how much companies pay in corporate taxes on income. Industry Tax Rates and Payments\\n\\nTable Summary: This table contains information about different industries, including the number of firms, total taxable income, total taxes paid, total cash taxes paid, cash taxes/accrual taxes, average across all companies, average across only money-making companies, aggregate tax rate, and average across only money-making companies2 and aggregate tax rate3. The data is organized in a tabular format and is delimited by a newline character, making it easy to read and analyze. This table provides valuable insights into the tax rates and payments of various industries, allowing for comparisons and further research on the financial performance of'}],\n",
       " 'totalbeta': [{'table_info': 'Table totalbeta has columns: Industry_Name (VARCHAR), Number_of_firms (INTEGER), Average_Unlevered_Beta (INTEGER), Average_Levered_Beta (INTEGER), Average_correlation_with_the_market (INTEGER), Total_Unlevered_Beta (INTEGER), Total_Levered_Beta (INTEGER)',\n",
       "   'table_summary': 'To estimate risk in a company from the perspective of  a completely undiversified investor (with all of his or her money invested just in one company). This table provides a summary of the financial characteristics of various industries, including the number of firms, average unlevered beta, average levered beta, average correlation with the market, total unlevered beta, and total levered beta. It can be used for comparison and analysis by investors, researchers, and analysts to understand the risk and return profiles of different industries.'}],\n",
       " 'wacc': [{'table_info': 'Table wacc has columns: Industry_Name (VARCHAR), Number_of_Firms (INTEGER), Beta (INTEGER), Cost_of_Equity (INTEGER), E_D_E_ (INTEGER), Std_Dev_in_Stock (INTEGER), Cost_of_Debt (INTEGER), Tax_Rate (INTEGER), After_tax_Cost_of_Debt (INTEGER), D_D_E_ (INTEGER), Cost_of_Capital (INTEGER), Cost_of_Capital_Local_Currency_ (INTEGER)',\n",
       "   'table_summary': 'To estimate the hurdle rate (required return) on both equity and overall capital invested for firms.. Industry Financial Metrics\\n\\nTable Summary: This table contains financial metrics for various industries, including the industry name, number of firms, beta, cost of equity, E/(D+E), standard deviation in stock, cost of debt, tax rate, after-tax cost of debt, D/(D+E), cost of capital, and cost of capital in local currency. It can be used for comparison and analysis by investors, financial analysts, and researchers.'}],\n",
       " 'wcdata': [{'table_info': 'Table wcdata has columns: Industry_Name (VARCHAR), Number_of_firms (INTEGER), Acc_Rec_Sales (INTEGER), Inventory_Sales (INTEGER), Acc_Pay_Sales (INTEGER), Non_cash_WC_Sales (INTEGER)',\n",
       "   'table_summary': 'To measure how much different working capital components are, as a percent of revenues.. This table contains financial metrics for various industries, including the number of firms, accounts receivable and sales, inventory and sales, accounts payable and sales, and non-cash working capital and sales. It provides a snapshot of the financial health of these industries and can be used for further analysis and decision making in the business world.'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_tb_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMBEDDINGS\n",
    "\n",
    "1. Embed the table summary and table SCHEMA to get the table that the user is looking for\n",
    "2. Embed the table rows for each table, so as to get relevant rows from the retrieved table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMBED THE TABLE SUMMARY AND TABLE SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from chromadb.utils.batch_utils import create_batches\n",
    "\n",
    "load_dotenv(override=True)\n",
    "emb_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=os.environ['OPENAI_API_KEY'],\n",
    "                model_name=\"text-embedding-3-small\")\n",
    "# EMBEDDING_MODEL = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
    "# emb_fn = embedding_functions.HuggingFaceEmbeddingFunction(model_name=EMBEDDING_MODEL,api_key=os.environ[\"HF_API_KEY\"])\n",
    "def embed_table_info(region:str,tb_dict):\n",
    "    client = chromadb.PersistentClient(path=f\"{region}_TABLE\")\n",
    "\n",
    "    table_collection = client.get_or_create_collection(name=\"table\",embedding_function=emb_fn)\n",
    "\n",
    "    table_docs = []\n",
    "    table_metadata = []\n",
    "\n",
    "\n",
    "    for table_name,table_data in tb_dict.items():\n",
    "        table_docs.append(table_data[0]['table_info'] + \". \" + table_data[0]['table_summary'])\n",
    "        table_metadata.append({\"table_name\":table_name,'table_metadata':table_data[0]['table_info']})\n",
    "    table_ids = [f\"id{i}\" for i in range(len(table_docs))]\n",
    "    assert len(table_docs) == len(table_metadata)\n",
    "\n",
    "    batches = create_batches(api=client,ids=table_ids, documents=table_docs, metadatas=table_metadata)\n",
    "    for batch in tqdm(batches,desc=\"Embedding table info\"):\n",
    "        table_collection.add(ids=batch[0],\n",
    "                    documents=batch[3],\n",
    "                    metadatas=batch[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"US\"\n",
    "\n",
    "def embed_rows(region:str,batch_size:int=24):\n",
    "    client = chromadb.PersistentClient(path=f\"{region}_TABLE\")\n",
    "\n",
    "    rows_collection = client.get_or_create_collection(name=\"rows\",embedding_function=emb_fn)\n",
    "\n",
    "    rows_docs = []\n",
    "    rows_metadata = []\n",
    "    region_path = os.path.join(processed_dir,region)\n",
    "    for df_path in os.listdir(region_path):\n",
    "        df_full_path = os.path.join(region_path,df_path)\n",
    "        df = pd.read_csv(df_full_path,index_col=False)\n",
    "        for idx,row in df.iterrows():\n",
    "            row_str = \"\"\n",
    "            for rv in row.values:\n",
    "                row_str+=str(rv) + \", \"\n",
    "                row_str = row_str.replace('\"',\"\")\n",
    "                row_str = row_str.replace(\"'\",'\"')\n",
    "            rows_docs.append(row_str[:-2])\n",
    "            rows_metadata.append({\"table_name\":df_path.split(\".\")[0],\"region\":region,\"index\":idx})\n",
    "    row_ids = [f\"id{i}\" for i in range(len(rows_docs))]\n",
    "    # print(len(rows_docs),len(rows_metadata))\n",
    "    assert len(rows_docs) == len(rows_metadata) == len(row_ids)\n",
    "\n",
    "    for start in tqdm(range(0,len(rows_docs),batch_size),desc=\"Embedding rows\"):\n",
    "        end = min(start+batch_size,len(rows_docs))\n",
    "        batch_ids = row_ids[start:end]\n",
    "        batch_rows = rows_docs[start:end]\n",
    "        batch_metadatas = rows_metadata[start:end]\n",
    "        rows_collection.add(ids=batch_ids,\n",
    "                    documents=batch_rows,\n",
    "                    metadatas=batch_metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding table info: 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "Embedding rows: 100%|██████████| 5/5 [01:09<00:00, 13.91s/it]\n"
     ]
    }
   ],
   "source": [
    "# region = \"US\"\n",
    "# embed_table_info(region,us_tb_dict)\n",
    "# embed_rows(region,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding table info: 100%|██████████| 1/1 [00:20<00:00, 20.73s/it]\n",
      "Embedding rows: 100%|██████████| 3/3 [00:50<00:00, 16.77s/it]\n"
     ]
    }
   ],
   "source": [
    "# region = \"India\"\n",
    "# embed_table_info(region,us_tb_dict)\n",
    "# embed_rows(region,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding table info: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "Embedding rows: 100%|██████████| 3/3 [00:49<00:00, 16.60s/it]\n"
     ]
    }
   ],
   "source": [
    "# region = \"China\"\n",
    "# embed_table_info(region,us_tb_dict)\n",
    "# embed_rows(region,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding table info: 100%|██████████| 1/1 [00:20<00:00, 20.69s/it]\n",
      "Embedding rows: 100%|██████████| 3/3 [01:09<00:00, 23.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# region = \"Europe\"\n",
    "# embed_table_info(region,us_tb_dict)\n",
    "# embed_rows(region,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding table info: 100%|██████████| 1/1 [00:20<00:00, 20.66s/it]\n",
      "Embedding rows: 100%|██████████| 3/3 [00:49<00:00, 16.37s/it]\n"
     ]
    }
   ],
   "source": [
    "# region = \"Global\"\n",
    "# embed_table_info(region,us_tb_dict)\n",
    "# embed_rows(region,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding table info: 100%|██████████| 1/1 [00:20<00:00, 20.73s/it]\n",
      "Embedding rows: 100%|██████████| 3/3 [01:13<00:00, 24.62s/it]\n"
     ]
    }
   ],
   "source": [
    "# region = \"Emerging\"\n",
    "# embed_table_info(region,us_tb_dict)\n",
    "# embed_rows(region,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding table info: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "Embedding rows: 100%|██████████| 3/3 [01:09<00:00, 23.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# region = \"Japan\"\n",
    "# embed_table_info(region,us_tb_dict)\n",
    "# embed_rows(region,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding table info: 100%|██████████| 1/1 [00:20<00:00, 20.70s/it]\n",
      "Embedding rows: 100%|██████████| 3/3 [00:48<00:00, 16.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# region = \"AUS_NZ_CANADA\"\n",
    "# embed_table_info(region,us_tb_dict)\n",
    "# embed_rows(region,1104)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT-TO-SQL PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"US\"\n",
    "\n",
    "db_dict = {\n",
    "    \"US\":us_engine,\n",
    "    \"India\":india_engine,\n",
    "    \"China\":china_engine,\n",
    "    \"Europe\":europe_engine,\n",
    "    \"Global\":global_engine,\n",
    "    \"AUS_NZ_CANADA\":aus_nz_canada_engine,\n",
    "    \"Japan\":japan_engine,\n",
    "    \"Emerging\":emerging_engine,\n",
    "}\n",
    "\n",
    "def get_collections_db(region:str):\n",
    "    client = chromadb.PersistentClient(path=f\"{region}_TABLE\")\n",
    "    table_collection = client.get_collection(name=\"table\",embedding_function=emb_fn)\n",
    "    row_collection = client.get_collection(name=\"rows\",embedding_function=emb_fn)\n",
    "    return [db_dict[region],table_collection,row_collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_collection_dict = {\n",
    "    \"US\":get_collections_db(\"US\"),\n",
    "    \"India\":get_collections_db(\"India\"),\n",
    "    \"China\":get_collections_db(\"China\"),\n",
    "    \"Europe\":get_collections_db(\"Europe\"),\n",
    "    \"Global\":get_collections_db(\"Global\"),\n",
    "    \"AUS_NZ_CANADA\":get_collections_db(\"AUS_NZ_CANADA\"),\n",
    "    \"Japan\":get_collections_db(\"Japan\"),\n",
    "    \"Emerging\":get_collections_db(\"Emerging\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Engine(sqlite:///US.db), Collection(name=table), Collection(name=rows)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_collection_dict['US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema 1: Table wcdata has columns: Industry_Name (VARCHAR), Number_of_firms (INTEGER), Acc_Rec_Sales (INTEGER), Inventory_Sales (INTEGER), Acc_Pay_Sales (INTEGER), Non_cash_WC_Sales (INTEGER)\n",
      "\tRow 1 from table wcdata: Environmental & Waste Services, 57, 0.1610239529643997, 0.0160835818498789, 0.0732441943895783, 0.1018059159059052\n",
      "\tRow 2 from table wcdata: Utility (Water), 13, 0.1519332278688117, 0.0326291583073621, 0.0835453907415389, 0.1135057399930943\n",
      "\tRow 3 from table wcdata: Software (Internet), 35, 0.1228885101454502, 1.6367264776917992e-05, 0.0423722824532171, 0.0966957543939344\n",
      "\tRow 4 from table wcdata: Packaging & Container, 22, 0.1374846253483106, 0.1265656973833159, 0.1305482832092476, 0.1112268155694879\n",
      "\tRow 5 from table wcdata: Semiconductor, 63, 0.1290909417966836, 0.1898317691334856, 0.0849115283669021, 0.2240302287823765\n",
      "\n",
      "\n",
      "Schema 2: Table wacc has columns: Industry_Name (VARCHAR), Number_of_Firms (INTEGER), Beta (INTEGER), Cost_of_Equity (INTEGER), E_D_E_ (INTEGER), Std_Dev_in_Stock (INTEGER), Cost_of_Debt (INTEGER), Tax_Rate (INTEGER), After_tax_Cost_of_Debt (INTEGER), D_D_E_ (INTEGER), Cost_of_Capital (INTEGER), Cost_of_Capital_Local_Currency_ (INTEGER)\n",
      "\tRow 1 from table wacc: Environmental & Waste Services, 57, 0.90699903446977, 0.0805219555856094, 0.8200309682356417, 0.4606641855124769, 0.050855, 0.0541917435398483, 0.03814125, 0.1799690317643583, 0.0728947410358769, 0.0728947410358769\n",
      "\tRow 2 from table wacc: Utility (Water), 13, 0.7139634340794939, 0.0716423179676567, 0.6627268690709837, 0.28198719816416, 0.050855, 0.1109172936995937, 0.03814125, 0.3372731309290163, 0.0603433078847393, 0.0603433078847392\n",
      "\tRow 3 from table wacc: Software (Internet), 35, 1.6160843271745926, 0.1131398790500312, 0.8930134645020447, 0.65221602599035, 0.060879, 0.0260557605345441, 0.04565925, 0.1069865354979553, 0.1059203603347457, 0.1059203603347458\n",
      "\tRow 4 from table wacc: Power, 50, 0.6506274182981785, 0.0687288612417162, 0.518339022067922, 0.2039437012455431, 0.045043, 0.1368565682061268, 0.03378225, 0.4816609779320779, 0.051896442295619, 0.0518964422956189\n",
      "\tRow 5 from table wacc: Packaging & Container, 22, 1.1327220379604754, 0.0909052137461818, 0.620115895714898, 0.2624270896574677, 0.050855, 0.1811910443993945, 0.03814125, 0.379884104285102, 0.0708610226399319, 0.0708610226399319\n",
      "\n",
      "\n",
      "Schema 3: Table goodwill has columns: Industry_Name (VARCHAR), Number_of_Firms (INTEGER), Goodwill_in_millions_ (INTEGER), Change_in_Goodwill_in_last_year (INTEGER), Goodwill_as_of_Total_Assets (INTEGER), Impairment_of_Goodwill_in_LTM_in_millioins (INTEGER), Impairment_as_of_Goodwill (INTEGER)\n",
      "\tRow 1 from table goodwill: Environmental & Waste Services, 57, 41368.444, 5543.546000000002, 0.3948996481872136, 15.278, 0.0003693153167665\n",
      "\tRow 2 from table goodwill: Utility (Water), 13, 4187.41, 13.519999999999529, 0.0702820236958313, 0.0, 0.0\n",
      "\tRow 3 from table goodwill: Software (Internet), 35, 21376.69, -1219.7700000000004, 0.3311515514892826, 484.91, 0.0226840544537063\n",
      "\tRow 4 from table goodwill: Semiconductor, 63, 173260.712, 1059.6019999999844, 0.2442931512253766, 429.63, 0.0024796735222928\n",
      "\tRow 5 from table goodwill: Power, 50, 71107.18000000001, 2563.4000000000087, 0.0438123430666786, 2078.7, 0.0292333348052897\n",
      "\n",
      "\n",
      "Schema 4: Table DollarUS has columns: Industry_Name (VARCHAR), Number_of_firms (INTEGER), Average_Company_Age_years_ (INTEGER), Market_Cap_millions_ (INTEGER), Book_Equity_millions_ (INTEGER), Enteprise_Value_millions_ (INTEGER), Invested_Capital_millions_ (INTEGER), Total_Debt_including_leases_millions_ (INTEGER), Revenues_millions_ (INTEGER), Gross_Profit_millions_ (INTEGER), EBITDA_millions_ (INTEGER), EBIT_Operating_Income_millions_ (INTEGER), Net_Income_millions_ (INTEGER)\n",
      "\tRow 1 from table DollarUS: Environmental & Waste Services, 57, 36.204081632653065, 203179.789, 27942.29500000001, 245587.91613806767, 33584.18642975343, 44591.084138067694, 72586.38100000002, 25147.858, 16003.036, 10021.184772386465, 5871.133\n",
      "\tRow 2 from table DollarUS: Utility (Water), 13, 89.61538461538461, 46874.02, 17109.9, 69973.57501678159, 39265.4050167816, 23854.997016781603, 8862.38, 4918.995, 4115.236000000001, 2719.0665966436786, 1713.7600000000002\n",
      "\tRow 3 from table DollarUS: Packaging & Container, 22, 80.19047619047619, 132627.167, 49084.58099999999, 205727.3441716776, 86259.32917167754, 81247.63917167754, 146995.2, 31917.63, 23820.874, 14660.644165664493, 4193.327999999999\n",
      "\tRow 4 from table DollarUS: Software (System & Application), 351, 20.125, 5277974.335000003, 397835.59000000014, 5446717.280701609, 326815.0326293967, 327430.6527016032, 508015.76600000006, 363334.808, 170251.41100000014, 128741.80425967928, 97238.32000000008\n",
      "\tRow 5 from table DollarUS: Software (Internet), 35, 14.413793103448276, 220091.11299999992, 28399.863, 241745.7304766904, 25653.71492597519, 26367.783476690336, 28838.050000000003, 17046.417999999998, 1980.7540000000004, -835.1582953380669, -4129.525\n",
      "\n",
      "\n",
      "Schema 5: Table divfcfe has columns: Industry_name (VARCHAR), Number_of_firms (INTEGER), _Dividends_ (INTEGER), _Net_Income_ (INTEGER), Payout (INTEGER), Dividends_Buybacks (INTEGER), Cash_Return_as_of_Net_Income (INTEGER), Dividends_Buybacks_Stock_Issuances (INTEGER), FCFE_before_debt_cash_flows_ (INTEGER), FCFE_after_debt_cash_flows_ (INTEGER), Net_Cash_Returned_FCFE_pre_debt_ (INTEGER), Net_Cash_Returned_FCFE_post_debt_ (INTEGER), Net_Cash_Returned_Net_Income (INTEGER), Cash_Firm_Value (INTEGER)\n",
      "\tRow 1 from table divfcfe: Environmental & Waste Services, 57, 2133.7000000000003, 5871.133, 0.3634221878468773, 4356.0830000000005, 0.7419492966689736, 3706.577, 4496.790999999999, 8844.003999999979, 0.824271574996481, 0.4191062102640398, 0.6313222677803416, 0.0088103858712382\n",
      "\tRow 2 from table divfcfe: Software (System & Application), 351, 26468.845, 97238.32000000008, 0.2722059060666615, 78137.651, 0.8035685005664427, 66388.049, 76723.88500000015, 92868.45200000016, 0.8652852889292542, 0.7148611565098542, 0.682735458613435, 0.0283097666177849\n",
      "\tRow 3 from table divfcfe: R.E.I.T., 193, 50197.926499999965, 23324.137999999984, 2.152187853630432, 43938.93199999997, 1.883839479941338, 18888.996999999978, 58792.15099999998, 108412.02399999648, 0.3212843326654264, 0.1742334134449938, 0.8098475922239866, 0.0188005563484407\n",
      "\tRow 4 from table divfcfe: Packaging & Container, 22, 2944.63, 4193.327999999999, 0.7022179042517068, 5178.039, 1.2348280411167458, 5090.014, 64.32999999999777, 2000.9439999999888, 79.12348826364335, 2.5438063234153625, 1.2138363610001417, 0.0380945383228542\n",
      "\tRow 5 from table divfcfe: Software (Entertainment), 84, 235.41, 93923.67300000004, 0.002506396869722, 90466.018, 0.9631865440356016, 89973.84199999999, 55413.70400000005, 62184.25100000004, 1.623674930663359, 1.44689114290369, 0.957946374179808, 0.0277904380642664\n",
      "\n",
      "\n",
      "\n",
      "Prediction(\n",
      "    rationale='find the effective tax rate of the software industry. We need to first identify the tax rate for the software industry from the wacc table.',\n",
      "    sql=\"```sql\\nSELECT DISTINCT wacc.Tax_Rate AS Effective_Tax_Rate\\nFROM wacc\\nWHERE wacc.Industry_Name = 'Software (Internet)';\\n```\"\n",
      ")\n",
      " Effective_Tax_Rate = 0.0260557605345441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from typing import List\n",
    "load_dotenv(override=True)\n",
    "text_to_sql = dspy.OpenAI(model='gpt-3.5-turbo', max_tokens=500)\n",
    "# text_to_sql = dspy.Claude(api_key=os.environ['ANTHROPIC_API_KEY'])\n",
    "sql_to_answer = dspy.OpenAI(model='gpt-3.5-turbo',max_tokens=1024)\n",
    "\n",
    "class TextToSQLAnswer(dspy.Signature):\n",
    "    \"\"\"Convert natural language text to SQL using suitable schema(s) from multiple schema choices\"\"\"\n",
    "\n",
    "    question:str = dspy.InputField(desc=\"natural language input which will be converted to SQL\")\n",
    "    relevant_table_schemas_rows:str = dspy.InputField(desc=\"Multiple possible tables which has table name and corresponding columns, along with relevant rows from the table (values in the same order as columns above)\")\n",
    "    sql:str = dspy.OutputField(desc=\"Generate syntactically correct sqlite query with correct column names using suitable tables(s) and its rows.\\n Don't forget to add distinct.\\n Please rename the returned columns into suitable names.\\n Don't output anything else other than the sqlite query\")\n",
    "    # schemas_used: List[str] = dspy.OutputField(desc=\"List of schemas from the provided schemas used to generate the SQL output\")\n",
    "# class SQLToAnswer(dspy.Signature):\n",
    "class SQLReturnToAnswer(dspy.Signature):\n",
    "    \"\"\"Answer the question using the rows from the SQL query\"\"\"\n",
    "    question:str = dspy.InputField()\n",
    "    sql:str = dspy.InputField(desc=\"sqlite query that generated the rows\")\n",
    "    # relevant_rows:str = dspy.InputField(desc=\"relevant rows in form of tuple (values in the same order as the select statement in the sql query)\")\n",
    "    relevant_rows:str = dspy.InputField(desc=\"relevant rows to answer the question\")\n",
    "    answer:str = dspy.OutputField(desc=\"answer to the question using relevant rows and the sql query\")\n",
    "\n",
    "class SQLRectifier(dspy.Signature):\n",
    "    \"\"\"Correct the SQL query to resolve the error using the proper table names, columns and rows\"\"\"  \n",
    "    input_sql:str = dspy.InputField(desc=\"sqlite query that needs to be fixed\")\n",
    "    error_str: str = dspy.InputField(desc=\"error that needs to be resolved\")\n",
    "    relevant_table_schemas_rows:str = dspy.InputField(desc=\"Multiple possible tables which has table name and corresponding columns, along with relevant rows from the table (values in the same order as columns above)\")\n",
    "    sql:str = dspy.OutputField(desc=\"corrected sqlite query to resolve the error and remove and any invalid syntax in the query.\\n Don't output anything else other than the sqlite query\")\n",
    "\n",
    "dspy.settings.configure(lm=text_to_sql)\n",
    "\n",
    "def process_sql_str(sql_str:str):\n",
    "    sql_str = sql_str.replace(\"```\",\"\")\n",
    "    sql_str = sql_str.replace(\"sql\",\"\")\n",
    "    sql_str = sql_str.strip()\n",
    "    return sql_str\n",
    "\n",
    "class TextToSQLQueryModule(dspy.Module):\n",
    "    def __init__(self,region:str,use_cot:bool=True,max_retries:int=2):\n",
    "        super().__init__()\n",
    "        self.region = region\n",
    "        db,table_collection,row_collection = db_collection_dict[region]\n",
    "        self.table_collection = table_collection\n",
    "        self.use_cot = use_cot\n",
    "        self.db = db\n",
    "        self.row_collection = row_collection\n",
    "        if self.use_cot == True:\n",
    "            self.sqlAnswer = dspy.ChainOfThought(TextToSQLAnswer)\n",
    "        else:\n",
    "            self.sqlAnswer = dspy.Predict(TextToSQLAnswer)\n",
    "        self.final_output = dspy.Predict(SQLReturnToAnswer)\n",
    "        self.max_tries = max_retries\n",
    "        self.sql_rectifier = dspy.ChainOfThought(SQLRectifier)\n",
    "    def forward(self,question:str):\n",
    "        question_emb = emb_fn.embed_with_retries(question)\n",
    "        docs = self.table_collection.query(\n",
    "            # query_texts=question,\n",
    "            query_embeddings = question_emb,\n",
    "            n_results = 5\n",
    "        )\n",
    "        # relevant_table_schemas = \"\"\n",
    "        relevant_rows_schemas = \"\"\n",
    "        existing_table_names = []\n",
    "        for table_idx,metadata_name in enumerate(docs['metadatas'][0]):\n",
    "            table_metadata = metadata_name['table_metadata']\n",
    "            # relevant_table_schemas += f'Schema {idx+1}: {table_metadata}\\n'\n",
    "            table_name = metadata_name['table_name']\n",
    "            if table_name in existing_table_names: \n",
    "                continue\n",
    "            existing_table_names.append(table_name)\n",
    "            # print(table_name)\n",
    "            rows = self.row_collection.query(\n",
    "                # query_texts=question,\n",
    "                query_embeddings = question_emb,\n",
    "                n_results = 5,\n",
    "                where = {\"table_name\":table_name}\n",
    "            )\n",
    "            relevant_rows_schemas += f'Schema {table_idx+1}: {table_metadata}\\n'\n",
    "            for row_idx,row in enumerate(rows['documents'][0]):\n",
    "                relevant_rows_schemas += f'\\tRow {row_idx+1} from table {table_name}: {row}\\n'\n",
    "            relevant_rows_schemas += '\\n\\n'\n",
    "        print(relevant_rows_schemas)\n",
    "        sql_query = self.sqlAnswer(question=question,relevant_table_schemas_rows=relevant_rows_schemas)\n",
    "        # return sql_query\n",
    "        num_tries = 0\n",
    "        print(sql_query)\n",
    "        while num_tries <= self.max_tries:\n",
    "            with us_engine.connect() as conn:\n",
    "                try:\n",
    "                    result = conn.execute(text(process_sql_str(sql_query.sql)))\n",
    "                    # print(\"Results: \",result.fetchall())\n",
    "                    # results = result.fetchall()\n",
    "                    # if results == []:\n",
    "                    #     sql_query = self.sql_rectifier(input_sql=sql_query.sql,error_str=\"No rows returned. Let's check the table names and row names step by step again and correct the sql query\",relevant_table_schemas_rows=relevant_rows_schemas)\n",
    "                    #     num_tries = self.max_tries\n",
    "                    num_tries = self.max_tries + 1\n",
    "                except Exception as error:\n",
    "                    # return sql_query,error\n",
    "                    sql_query = self.sql_rectifier(input_sql=sql_query.sql,error_str=str(error),relevant_table_schemas_rows=relevant_rows_schemas)\n",
    "                    num_tries += 1\n",
    "                    print(sql_query)\n",
    "                    if num_tries == self.max_tries:\n",
    "                        return sql_query,error\n",
    "\n",
    "        with dspy.context(lm=sql_to_answer):\n",
    "            row_str = \"\"\n",
    "            key = tuple(result.keys())\n",
    "            for row in result.fetchall():\n",
    "                for r,k in zip(row,key):\n",
    "                    row_str += f\" {k} = {r},\"\n",
    "                row_str = row_str[:-1]\n",
    "                row_str += \"\\n\"\n",
    "            print(row_str)\n",
    "            final_answer = self.final_output(question=question,sql=sql_query.sql,relevant_rows=row_str)\n",
    "            return final_answer\n",
    "\n",
    "tsql = TextToSQLQueryModule(\"US\")\n",
    "sq = tsql(question=\"What is the effective tax rate of software industry?\")\n",
    "# sq = tsql(question=\"What is the beta value and number of firms for all the Software industries and semiconductor industry?\")\n",
    "# sq = tsql(\"What is the debt to EBITDA ratio for software industry?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='The effective tax rate of the software industry is 0.0260557605345441.'\n",
       ")"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The effective tax rate of the software industry is 0.0260557605345441.\n"
     ]
    }
   ],
   "source": [
    "print(sq.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
